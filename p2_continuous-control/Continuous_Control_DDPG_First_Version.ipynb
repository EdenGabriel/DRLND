{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control First Version (DDPG)\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use Unity ML-Agents environment for the second project (first version) of the **Deep Reinforcement Learning Nanodegree program**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start the Environment\n",
    "\n",
    "Please refer to the file `README.md` for environment preparation.\n",
    "\n",
    "Firstly, we begin by importing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "from collections import deque, namedtuple, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from unityagents import UnityEnvironment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will start the environment. \n",
    "\n",
    "Please change the `file_name` parameter to match the real location of the Unity Environment that on your desktop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64', no_graphics=True)\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n",
      "(33,) (33,)\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents, env_info.vector_observations.shape[0])\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n",
    "\n",
    "print(states[0].shape, states[0,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training the Agent (using DDPG)\n",
    "Train the agent to solve the environment.\n",
    "\n",
    "The `Agent` contains 4 models: `actor_local`, `actor_target`, `critic_local`, `critic_target`. \n",
    "\n",
    "The **Actor model** structure are as follows:\n",
    "![actor_model](resources/actor_model.png)\n",
    "\n",
    "\n",
    "The **Critic model** structure are as follows:\n",
    "![critic_model](resources/critic_model.png)\n",
    "\n",
    "The following are training codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg_agent import Agent\n",
    "\n",
    "# ddpg function for single and multiple agents\n",
    "def ddpg(n_episodes=100,\n",
    "         eps_start=1.0, eps_decay=1e-5, eps_end=0.05,\n",
    "         max_t=10000, learn_every_step=100):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores, actor_losses, critic_losses = [], [], []\n",
    "    eps = eps_start\n",
    "    for i_episode in range(1, 1 + n_episodes):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "\n",
    "        agent.reset()\n",
    "\n",
    "        avg_score = 0\n",
    "        actor_loss_list, critic_loss_list = [], []\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states, add_noise=random.random() < eps)\n",
    "            eps = max(eps - eps_decay, eps_end)\n",
    "\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "\n",
    "            # Learn, if enough samples are available in memory\n",
    "            if len(agent.memory) > agent.batch_size and \\\n",
    "                    t % learn_every_step == 0:\n",
    "                for _ in range(3):\n",
    "                    experiences = agent.memory.sample(batch_size=agent.batch_size)\n",
    "                    actor_loss, critic_loss = agent.learn(experiences, agent.gamma,\n",
    "                                                          last_action_loss=actor_loss_list[-1] if actor_loss_list else None)\n",
    "                    actor_loss_list.append(actor_loss)\n",
    "                    critic_loss_list.append(critic_loss)\n",
    "\n",
    "            avg_score += np.mean(rewards)\n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break\n",
    "\n",
    "        scores_deque.append(avg_score)\n",
    "        scores.append(avg_score)\n",
    "        actor_losses.append(np.mean(actor_loss_list))\n",
    "        critic_losses.append(np.mean(critic_loss_list))\n",
    "        print(f\"\\rEpisode {i_episode}\\tExploration: {eps:.6f}\\t\"\n",
    "              f\"Average Score: {np.mean(scores_deque):.2f}\\tCurrent Score: {avg_score:.2f}\\t\"\n",
    "              f\"Actor Loss: {np.mean(actor_loss_list):.2e}\\tCritic Loss: {np.mean(critic_loss_list):.2e}\")\n",
    "\n",
    "        if i_episode % 100 == 0:\n",
    "            # agent.save()\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "\n",
    "        if np.mean(scores_deque) > 30 and len(scores_deque) >= 100:\n",
    "            agent.save()\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            break\n",
    "\n",
    "    return scores, actor_losses, critic_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global parameters\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "ACTOR_LR = 1e-4  # learning rate\n",
    "ACTOR_HIDDEN_UNITS = (256, 128)\n",
    "ACTOR_WEIGHT_DECAY = 1e-5\n",
    "\n",
    "CRITIC_LR = 1e-4  # learning rate\n",
    "CRITIC_HIDDEN_UNITS = (256, 128)\n",
    "CRITIC_WEIGHT_DECAY = 1e-5\n",
    "\n",
    "MEMORY_BUFFER_SIZE = int(1e6)  # maximum size of replay buffer\n",
    "BATCH_SIZE = 128  # mini-batch size\n",
    "GAMMA = 0.99  # discount factor\n",
    "TAU = 1e-3  # interpolation parameter\n",
    "\n",
    "N_EPISODES = 2000  # total episodes to train\n",
    "EPS_START = 1.0  # initial value for exploration (epsilon)\n",
    "EPS_DECAY = 2e-5  # epsilon decay value after each step\n",
    "EPS_END = 0.05  # lower limit of epsilon\n",
    "MAX_STEPS = 10000  # maximum training steps of each epoch\n",
    "LEARN_EVERY_STEP = 20  # extra learning after every step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=state_size,\n",
    "              action_size=action_size,\n",
    "              num_agents=num_agents,\n",
    "              seed=SEED, buffer_size=MEMORY_BUFFER_SIZE,\n",
    "              actor_lr=ACTOR_LR, actor_hidden_sizes=ACTOR_HIDDEN_UNITS, actor_weight_decay=ACTOR_WEIGHT_DECAY,\n",
    "              critic_lr=CRITIC_LR, critic_hidden_sizes=CRITIC_HIDDEN_UNITS, critic_weight_decay=CRITIC_WEIGHT_DECAY,\n",
    "              batch_size=BATCH_SIZE, gamma=GAMMA, tau=TAU)\n",
    "#print(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor(\n",
      "  (fc_body): Sequential(\n",
      "    (0): Linear(in_features=33, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "    (5): Tanh()\n",
      "  )\n",
      ")\n",
      "Critic(\n",
      "  (fc_body): Sequential(\n",
      "    (0): Linear(in_features=33, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01, inplace)\n",
      "  )\n",
      "  (critic_body): Sequential(\n",
      "    (0): Linear(in_features=260, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Episode 1\tExploration: 0.979980\tAverage Score: 0.37\tCurrent Score: 0.37\tActor Loss: -9.01e-03\tCritic Loss: 5.25e-06\n",
      "Episode 2\tExploration: 0.959960\tAverage Score: 0.34\tCurrent Score: 0.32\tActor Loss: -1.48e-02\tCritic Loss: 7.73e-06\n",
      "Episode 3\tExploration: 0.939940\tAverage Score: 0.23\tCurrent Score: 0.00\tActor Loss: -1.81e-02\tCritic Loss: 7.28e-06\n",
      "Episode 4\tExploration: 0.919920\tAverage Score: 0.24\tCurrent Score: 0.29\tActor Loss: -1.95e-02\tCritic Loss: 8.57e-06\n",
      "Episode 5\tExploration: 0.899900\tAverage Score: 0.31\tCurrent Score: 0.57\tActor Loss: -2.14e-02\tCritic Loss: 1.03e-05\n",
      "Episode 6\tExploration: 0.879880\tAverage Score: 0.30\tCurrent Score: 0.27\tActor Loss: -2.50e-02\tCritic Loss: 1.04e-05\n",
      "Episode 7\tExploration: 0.859860\tAverage Score: 0.34\tCurrent Score: 0.58\tActor Loss: -2.78e-02\tCritic Loss: 1.25e-05\n",
      "Episode 8\tExploration: 0.839840\tAverage Score: 0.33\tCurrent Score: 0.23\tActor Loss: -3.06e-02\tCritic Loss: 1.16e-05\n",
      "Episode 9\tExploration: 0.819820\tAverage Score: 0.33\tCurrent Score: 0.35\tActor Loss: -3.31e-02\tCritic Loss: 1.17e-05\n",
      "Episode 10\tExploration: 0.799800\tAverage Score: 0.35\tCurrent Score: 0.57\tActor Loss: -3.52e-02\tCritic Loss: 1.33e-05\n",
      "Episode 11\tExploration: 0.779780\tAverage Score: 0.42\tCurrent Score: 1.08\tActor Loss: -3.74e-02\tCritic Loss: 1.27e-05\n",
      "Episode 12\tExploration: 0.759760\tAverage Score: 0.40\tCurrent Score: 0.23\tActor Loss: -3.92e-02\tCritic Loss: 1.34e-05\n",
      "Episode 13\tExploration: 0.739740\tAverage Score: 0.41\tCurrent Score: 0.46\tActor Loss: -4.13e-02\tCritic Loss: 1.40e-05\n",
      "Episode 14\tExploration: 0.719720\tAverage Score: 0.55\tCurrent Score: 2.41\tActor Loss: -4.34e-02\tCritic Loss: 1.57e-05\n",
      "Episode 15\tExploration: 0.699700\tAverage Score: 0.58\tCurrent Score: 1.02\tActor Loss: -4.64e-02\tCritic Loss: 1.69e-05\n",
      "Episode 16\tExploration: 0.679680\tAverage Score: 0.67\tCurrent Score: 1.92\tActor Loss: -4.91e-02\tCritic Loss: 2.00e-05\n",
      "Episode 17\tExploration: 0.659660\tAverage Score: 0.76\tCurrent Score: 2.27\tActor Loss: -5.22e-02\tCritic Loss: 2.14e-05\n",
      "Episode 18\tExploration: 0.639640\tAverage Score: 0.75\tCurrent Score: 0.54\tActor Loss: -5.49e-02\tCritic Loss: 2.55e-05\n",
      "Episode 19\tExploration: 0.619620\tAverage Score: 0.80\tCurrent Score: 1.76\tActor Loss: -5.85e-02\tCritic Loss: 2.66e-05\n",
      "Episode 20\tExploration: 0.599600\tAverage Score: 0.83\tCurrent Score: 1.37\tActor Loss: -6.13e-02\tCritic Loss: 2.95e-05\n",
      "Episode 21\tExploration: 0.579580\tAverage Score: 0.79\tCurrent Score: 0.00\tActor Loss: -6.44e-02\tCritic Loss: 3.14e-05\n",
      "Episode 22\tExploration: 0.559560\tAverage Score: 0.85\tCurrent Score: 2.11\tActor Loss: -6.71e-02\tCritic Loss: 3.59e-05\n",
      "Episode 23\tExploration: 0.539540\tAverage Score: 1.00\tCurrent Score: 4.18\tActor Loss: -7.10e-02\tCritic Loss: 4.18e-05\n",
      "Episode 24\tExploration: 0.519520\tAverage Score: 1.07\tCurrent Score: 2.67\tActor Loss: -7.41e-02\tCritic Loss: 4.44e-05\n",
      "Episode 25\tExploration: 0.499500\tAverage Score: 1.08\tCurrent Score: 1.32\tActor Loss: -7.85e-02\tCritic Loss: 4.94e-05\n",
      "Episode 26\tExploration: 0.479480\tAverage Score: 1.19\tCurrent Score: 4.13\tActor Loss: -8.20e-02\tCritic Loss: 5.43e-05\n",
      "Episode 27\tExploration: 0.459460\tAverage Score: 1.23\tCurrent Score: 2.19\tActor Loss: -8.65e-02\tCritic Loss: 5.86e-05\n",
      "Episode 28\tExploration: 0.439440\tAverage Score: 1.26\tCurrent Score: 2.12\tActor Loss: -9.09e-02\tCritic Loss: 6.48e-05\n",
      "Episode 29\tExploration: 0.419420\tAverage Score: 1.25\tCurrent Score: 0.83\tActor Loss: -9.59e-02\tCritic Loss: 7.12e-05\n",
      "Episode 30\tExploration: 0.399400\tAverage Score: 1.34\tCurrent Score: 4.18\tActor Loss: -1.01e-01\tCritic Loss: 8.17e-05\n",
      "Episode 31\tExploration: 0.379380\tAverage Score: 1.36\tCurrent Score: 1.84\tActor Loss: -1.06e-01\tCritic Loss: 8.67e-05\n",
      "Episode 32\tExploration: 0.359360\tAverage Score: 1.42\tCurrent Score: 3.27\tActor Loss: -1.12e-01\tCritic Loss: 8.50e-05\n",
      "Episode 33\tExploration: 0.339340\tAverage Score: 1.47\tCurrent Score: 3.07\tActor Loss: -1.16e-01\tCritic Loss: 9.69e-05\n",
      "Episode 34\tExploration: 0.319320\tAverage Score: 1.55\tCurrent Score: 4.28\tActor Loss: -1.24e-01\tCritic Loss: 1.04e-04\n",
      "Episode 35\tExploration: 0.299300\tAverage Score: 1.64\tCurrent Score: 4.43\tActor Loss: -1.29e-01\tCritic Loss: 1.16e-04\n",
      "Episode 36\tExploration: 0.279280\tAverage Score: 1.68\tCurrent Score: 3.22\tActor Loss: -1.36e-01\tCritic Loss: 1.29e-04\n",
      "Episode 37\tExploration: 0.259260\tAverage Score: 1.72\tCurrent Score: 3.30\tActor Loss: -1.44e-01\tCritic Loss: 1.39e-04\n",
      "Episode 38\tExploration: 0.239240\tAverage Score: 1.83\tCurrent Score: 5.95\tActor Loss: -1.51e-01\tCritic Loss: 1.56e-04\n",
      "Episode 39\tExploration: 0.219220\tAverage Score: 1.90\tCurrent Score: 4.41\tActor Loss: -1.57e-01\tCritic Loss: 1.50e-04\n",
      "Episode 40\tExploration: 0.199200\tAverage Score: 1.96\tCurrent Score: 4.29\tActor Loss: -1.65e-01\tCritic Loss: 1.70e-04\n",
      "Episode 41\tExploration: 0.179180\tAverage Score: 2.01\tCurrent Score: 4.08\tActor Loss: -1.71e-01\tCritic Loss: 1.75e-04\n",
      "Episode 42\tExploration: 0.159160\tAverage Score: 2.07\tCurrent Score: 4.50\tActor Loss: -1.78e-01\tCritic Loss: 1.91e-04\n",
      "Episode 43\tExploration: 0.139140\tAverage Score: 2.18\tCurrent Score: 6.59\tActor Loss: -1.86e-01\tCritic Loss: 2.05e-04\n",
      "Episode 44\tExploration: 0.119120\tAverage Score: 2.32\tCurrent Score: 8.36\tActor Loss: -1.95e-01\tCritic Loss: 2.03e-04\n",
      "Episode 45\tExploration: 0.099100\tAverage Score: 2.41\tCurrent Score: 6.72\tActor Loss: -2.03e-01\tCritic Loss: 2.36e-04\n",
      "Episode 46\tExploration: 0.079080\tAverage Score: 2.50\tCurrent Score: 6.25\tActor Loss: -2.10e-01\tCritic Loss: 2.45e-04\n",
      "Episode 47\tExploration: 0.059060\tAverage Score: 2.61\tCurrent Score: 7.80\tActor Loss: -2.21e-01\tCritic Loss: 2.42e-04\n",
      "Episode 48\tExploration: 0.050000\tAverage Score: 2.79\tCurrent Score: 11.03\tActor Loss: -2.28e-01\tCritic Loss: 2.68e-04\n",
      "Episode 49\tExploration: 0.050000\tAverage Score: 2.88\tCurrent Score: 7.15\tActor Loss: -2.36e-01\tCritic Loss: 2.79e-04\n",
      "Episode 50\tExploration: 0.050000\tAverage Score: 2.94\tCurrent Score: 5.99\tActor Loss: -2.45e-01\tCritic Loss: 3.04e-04\n",
      "Episode 51\tExploration: 0.050000\tAverage Score: 3.06\tCurrent Score: 9.29\tActor Loss: -2.54e-01\tCritic Loss: 3.22e-04\n",
      "Episode 52\tExploration: 0.050000\tAverage Score: 3.17\tCurrent Score: 8.80\tActor Loss: -2.63e-01\tCritic Loss: 3.27e-04\n",
      "Episode 53\tExploration: 0.050000\tAverage Score: 3.30\tCurrent Score: 9.78\tActor Loss: -2.72e-01\tCritic Loss: 3.57e-04\n",
      "Episode 54\tExploration: 0.050000\tAverage Score: 3.35\tCurrent Score: 6.06\tActor Loss: -2.82e-01\tCritic Loss: 3.89e-04\n",
      "Episode 55\tExploration: 0.050000\tAverage Score: 3.45\tCurrent Score: 8.99\tActor Loss: -2.90e-01\tCritic Loss: 3.76e-04\n",
      "Episode 56\tExploration: 0.050000\tAverage Score: 3.54\tCurrent Score: 8.65\tActor Loss: -2.99e-01\tCritic Loss: 4.01e-04\n",
      "Episode 57\tExploration: 0.050000\tAverage Score: 3.64\tCurrent Score: 8.82\tActor Loss: -3.07e-01\tCritic Loss: 4.13e-04\n",
      "Episode 58\tExploration: 0.050000\tAverage Score: 3.76\tCurrent Score: 10.84\tActor Loss: -3.17e-01\tCritic Loss: 4.51e-04\n",
      "Episode 59\tExploration: 0.050000\tAverage Score: 3.80\tCurrent Score: 6.20\tActor Loss: -3.29e-01\tCritic Loss: 4.73e-04\n",
      "Episode 60\tExploration: 0.050000\tAverage Score: 3.88\tCurrent Score: 8.23\tActor Loss: -3.37e-01\tCritic Loss: 5.07e-04\n",
      "Episode 61\tExploration: 0.050000\tAverage Score: 3.91\tCurrent Score: 5.85\tActor Loss: -3.44e-01\tCritic Loss: 5.06e-04\n",
      "Episode 62\tExploration: 0.050000\tAverage Score: 3.93\tCurrent Score: 5.36\tActor Loss: -3.56e-01\tCritic Loss: 5.23e-04\n",
      "Episode 63\tExploration: 0.050000\tAverage Score: 4.07\tCurrent Score: 12.48\tActor Loss: -3.67e-01\tCritic Loss: 5.36e-04\n",
      "Episode 64\tExploration: 0.050000\tAverage Score: 4.02\tCurrent Score: 1.28\tActor Loss: -3.76e-01\tCritic Loss: 5.66e-04\n",
      "Episode 65\tExploration: 0.050000\tAverage Score: 4.10\tCurrent Score: 8.79\tActor Loss: -3.84e-01\tCritic Loss: 5.92e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 66\tExploration: 0.050000\tAverage Score: 4.16\tCurrent Score: 8.50\tActor Loss: -3.93e-01\tCritic Loss: 6.04e-04\n",
      "Episode 67\tExploration: 0.050000\tAverage Score: 4.19\tCurrent Score: 5.84\tActor Loss: -4.02e-01\tCritic Loss: 5.75e-04\n",
      "Episode 68\tExploration: 0.050000\tAverage Score: 4.18\tCurrent Score: 3.62\tActor Loss: -4.13e-01\tCritic Loss: 6.26e-04\n",
      "Episode 69\tExploration: 0.050000\tAverage Score: 4.28\tCurrent Score: 11.29\tActor Loss: -4.22e-01\tCritic Loss: 7.09e-04\n",
      "Episode 70\tExploration: 0.050000\tAverage Score: 4.43\tCurrent Score: 14.87\tActor Loss: -4.38e-01\tCritic Loss: 6.85e-04\n",
      "Episode 71\tExploration: 0.050000\tAverage Score: 4.53\tCurrent Score: 11.51\tActor Loss: -4.45e-01\tCritic Loss: 7.13e-04\n",
      "Episode 72\tExploration: 0.050000\tAverage Score: 4.57\tCurrent Score: 6.97\tActor Loss: -4.55e-01\tCritic Loss: 7.07e-04\n",
      "Episode 73\tExploration: 0.050000\tAverage Score: 4.63\tCurrent Score: 9.05\tActor Loss: -4.69e-01\tCritic Loss: 7.79e-04\n",
      "Episode 74\tExploration: 0.050000\tAverage Score: 4.68\tCurrent Score: 8.51\tActor Loss: -4.76e-01\tCritic Loss: 7.95e-04\n",
      "Episode 75\tExploration: 0.050000\tAverage Score: 4.66\tCurrent Score: 2.98\tActor Loss: -4.88e-01\tCritic Loss: 8.83e-04\n",
      "Episode 76\tExploration: 0.050000\tAverage Score: 4.73\tCurrent Score: 9.93\tActor Loss: -4.97e-01\tCritic Loss: 8.40e-04\n",
      "Episode 77\tExploration: 0.050000\tAverage Score: 4.84\tCurrent Score: 12.95\tActor Loss: -5.09e-01\tCritic Loss: 8.61e-04\n",
      "Episode 78\tExploration: 0.050000\tAverage Score: 4.84\tCurrent Score: 5.60\tActor Loss: -5.20e-01\tCritic Loss: 8.71e-04\n",
      "Episode 79\tExploration: 0.050000\tAverage Score: 4.86\tCurrent Score: 5.67\tActor Loss: -5.27e-01\tCritic Loss: 8.93e-04\n",
      "Episode 80\tExploration: 0.050000\tAverage Score: 4.88\tCurrent Score: 6.68\tActor Loss: -5.38e-01\tCritic Loss: 8.59e-04\n",
      "Episode 81\tExploration: 0.050000\tAverage Score: 4.89\tCurrent Score: 6.07\tActor Loss: -5.46e-01\tCritic Loss: 9.44e-04\n",
      "Episode 82\tExploration: 0.050000\tAverage Score: 4.91\tCurrent Score: 6.21\tActor Loss: -5.57e-01\tCritic Loss: 9.70e-04\n",
      "Episode 83\tExploration: 0.050000\tAverage Score: 4.99\tCurrent Score: 11.34\tActor Loss: -5.68e-01\tCritic Loss: 1.02e-03\n",
      "Episode 84\tExploration: 0.050000\tAverage Score: 5.07\tCurrent Score: 11.66\tActor Loss: -5.80e-01\tCritic Loss: 1.04e-03\n",
      "Episode 85\tExploration: 0.050000\tAverage Score: 5.08\tCurrent Score: 6.61\tActor Loss: -5.90e-01\tCritic Loss: 1.27e-03\n",
      "Episode 86\tExploration: 0.050000\tAverage Score: 5.13\tCurrent Score: 9.05\tActor Loss: -6.02e-01\tCritic Loss: 1.07e-03\n",
      "Episode 87\tExploration: 0.050000\tAverage Score: 5.14\tCurrent Score: 5.72\tActor Loss: -6.09e-01\tCritic Loss: 1.07e-03\n",
      "Episode 88\tExploration: 0.050000\tAverage Score: 5.13\tCurrent Score: 4.92\tActor Loss: -6.18e-01\tCritic Loss: 1.14e-03\n",
      "Episode 89\tExploration: 0.050000\tAverage Score: 5.29\tCurrent Score: 18.89\tActor Loss: -6.27e-01\tCritic Loss: 1.17e-03\n",
      "Episode 90\tExploration: 0.050000\tAverage Score: 5.34\tCurrent Score: 10.20\tActor Loss: -6.39e-01\tCritic Loss: 1.24e-03\n",
      "Episode 91\tExploration: 0.050000\tAverage Score: 5.46\tCurrent Score: 15.50\tActor Loss: -6.51e-01\tCritic Loss: 1.20e-03\n",
      "Episode 92\tExploration: 0.050000\tAverage Score: 5.51\tCurrent Score: 10.66\tActor Loss: -6.59e-01\tCritic Loss: 1.14e-03\n",
      "Episode 93\tExploration: 0.050000\tAverage Score: 5.62\tCurrent Score: 15.44\tActor Loss: -6.71e-01\tCritic Loss: 1.16e-03\n",
      "Episode 94\tExploration: 0.050000\tAverage Score: 5.64\tCurrent Score: 7.80\tActor Loss: -6.82e-01\tCritic Loss: 1.37e-03\n",
      "Episode 95\tExploration: 0.050000\tAverage Score: 5.72\tCurrent Score: 12.71\tActor Loss: -6.88e-01\tCritic Loss: 1.23e-03\n",
      "Episode 96\tExploration: 0.050000\tAverage Score: 5.73\tCurrent Score: 7.08\tActor Loss: -7.02e-01\tCritic Loss: 1.21e-03\n",
      "Episode 97\tExploration: 0.050000\tAverage Score: 5.75\tCurrent Score: 7.81\tActor Loss: -7.09e-01\tCritic Loss: 1.32e-03\n",
      "Episode 98\tExploration: 0.050000\tAverage Score: 5.82\tCurrent Score: 11.96\tActor Loss: -7.18e-01\tCritic Loss: 1.31e-03\n",
      "Episode 99\tExploration: 0.050000\tAverage Score: 5.87\tCurrent Score: 11.72\tActor Loss: -7.27e-01\tCritic Loss: 1.26e-03\n",
      "Episode 100\tExploration: 0.050000\tAverage Score: 5.93\tCurrent Score: 11.68\tActor Loss: -7.35e-01\tCritic Loss: 1.45e-03\n",
      "Episode 100\tAverage Score: 5.93\n",
      "Episode 101\tExploration: 0.050000\tAverage Score: 6.04\tCurrent Score: 10.81\tActor Loss: -7.46e-01\tCritic Loss: 1.47e-03\n",
      "Episode 102\tExploration: 0.050000\tAverage Score: 6.16\tCurrent Score: 12.30\tActor Loss: -7.55e-01\tCritic Loss: 1.58e-03\n",
      "Episode 103\tExploration: 0.050000\tAverage Score: 6.22\tCurrent Score: 6.03\tActor Loss: -7.67e-01\tCritic Loss: 1.51e-03\n",
      "Episode 104\tExploration: 0.050000\tAverage Score: 6.33\tCurrent Score: 11.59\tActor Loss: -7.74e-01\tCritic Loss: 1.43e-03\n",
      "Episode 105\tExploration: 0.050000\tAverage Score: 6.40\tCurrent Score: 7.98\tActor Loss: -7.81e-01\tCritic Loss: 1.41e-03\n",
      "Episode 106\tExploration: 0.050000\tAverage Score: 6.52\tCurrent Score: 11.69\tActor Loss: -7.92e-01\tCritic Loss: 1.53e-03\n",
      "Episode 107\tExploration: 0.050000\tAverage Score: 6.61\tCurrent Score: 9.79\tActor Loss: -7.99e-01\tCritic Loss: 1.62e-03\n",
      "Episode 108\tExploration: 0.050000\tAverage Score: 6.67\tCurrent Score: 6.52\tActor Loss: -8.07e-01\tCritic Loss: 1.51e-03\n",
      "Episode 109\tExploration: 0.050000\tAverage Score: 6.80\tCurrent Score: 13.02\tActor Loss: -8.13e-01\tCritic Loss: 1.53e-03\n",
      "Episode 110\tExploration: 0.050000\tAverage Score: 6.91\tCurrent Score: 11.04\tActor Loss: -8.23e-01\tCritic Loss: 1.50e-03\n",
      "Episode 111\tExploration: 0.050000\tAverage Score: 6.97\tCurrent Score: 7.91\tActor Loss: -8.35e-01\tCritic Loss: 1.66e-03\n",
      "Episode 112\tExploration: 0.050000\tAverage Score: 7.05\tCurrent Score: 8.09\tActor Loss: -8.41e-01\tCritic Loss: 1.57e-03\n",
      "Episode 113\tExploration: 0.050000\tAverage Score: 7.12\tCurrent Score: 7.72\tActor Loss: -8.49e-01\tCritic Loss: 1.57e-03\n",
      "Episode 114\tExploration: 0.050000\tAverage Score: 7.20\tCurrent Score: 10.02\tActor Loss: -8.58e-01\tCritic Loss: 1.58e-03\n",
      "Episode 115\tExploration: 0.050000\tAverage Score: 7.34\tCurrent Score: 14.54\tActor Loss: -8.65e-01\tCritic Loss: 1.81e-03\n",
      "Episode 116\tExploration: 0.050000\tAverage Score: 7.39\tCurrent Score: 7.43\tActor Loss: -8.74e-01\tCritic Loss: 1.74e-03\n",
      "Episode 117\tExploration: 0.050000\tAverage Score: 7.51\tCurrent Score: 14.42\tActor Loss: -8.82e-01\tCritic Loss: 1.85e-03\n",
      "Episode 118\tExploration: 0.050000\tAverage Score: 7.57\tCurrent Score: 6.52\tActor Loss: -8.89e-01\tCritic Loss: 1.61e-03\n",
      "Episode 119\tExploration: 0.050000\tAverage Score: 7.65\tCurrent Score: 9.86\tActor Loss: -8.97e-01\tCritic Loss: 1.92e-03\n",
      "Episode 120\tExploration: 0.050000\tAverage Score: 7.74\tCurrent Score: 10.49\tActor Loss: -9.05e-01\tCritic Loss: 1.82e-03\n",
      "Episode 121\tExploration: 0.050000\tAverage Score: 7.82\tCurrent Score: 7.13\tActor Loss: -9.15e-01\tCritic Loss: 1.76e-03\n",
      "Episode 122\tExploration: 0.050000\tAverage Score: 7.91\tCurrent Score: 11.66\tActor Loss: -9.17e-01\tCritic Loss: 1.69e-03\n",
      "Episode 123\tExploration: 0.050000\tAverage Score: 7.97\tCurrent Score: 10.55\tActor Loss: -9.27e-01\tCritic Loss: 1.79e-03\n",
      "Episode 124\tExploration: 0.050000\tAverage Score: 8.06\tCurrent Score: 11.19\tActor Loss: -9.32e-01\tCritic Loss: 2.05e-03\n",
      "Episode 125\tExploration: 0.050000\tAverage Score: 8.19\tCurrent Score: 14.56\tActor Loss: -9.43e-01\tCritic Loss: 2.11e-03\n",
      "Episode 126\tExploration: 0.050000\tAverage Score: 8.27\tCurrent Score: 11.58\tActor Loss: -9.54e-01\tCritic Loss: 1.83e-03\n",
      "Episode 127\tExploration: 0.050000\tAverage Score: 8.43\tCurrent Score: 18.44\tActor Loss: -9.61e-01\tCritic Loss: 2.07e-03\n",
      "Episode 128\tExploration: 0.050000\tAverage Score: 8.53\tCurrent Score: 12.57\tActor Loss: -9.71e-01\tCritic Loss: 1.91e-03\n",
      "Episode 129\tExploration: 0.050000\tAverage Score: 8.68\tCurrent Score: 15.74\tActor Loss: -9.78e-01\tCritic Loss: 2.13e-03\n",
      "Episode 130\tExploration: 0.050000\tAverage Score: 8.71\tCurrent Score: 6.59\tActor Loss: -9.86e-01\tCritic Loss: 2.12e-03\n",
      "Episode 131\tExploration: 0.050000\tAverage Score: 8.80\tCurrent Score: 11.39\tActor Loss: -9.94e-01\tCritic Loss: 2.41e-03\n",
      "Episode 132\tExploration: 0.050000\tAverage Score: 8.87\tCurrent Score: 9.73\tActor Loss: -1.00e+00\tCritic Loss: 2.08e-03\n",
      "Episode 133\tExploration: 0.050000\tAverage Score: 9.00\tCurrent Score: 16.13\tActor Loss: -1.01e+00\tCritic Loss: 2.06e-03\n",
      "Episode 134\tExploration: 0.050000\tAverage Score: 9.05\tCurrent Score: 9.02\tActor Loss: -1.02e+00\tCritic Loss: 2.33e-03\n",
      "Episode 135\tExploration: 0.050000\tAverage Score: 9.15\tCurrent Score: 14.60\tActor Loss: -1.02e+00\tCritic Loss: 2.63e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 136\tExploration: 0.050000\tAverage Score: 9.29\tCurrent Score: 17.24\tActor Loss: -1.03e+00\tCritic Loss: 2.08e-03\n",
      "Episode 137\tExploration: 0.050000\tAverage Score: 9.43\tCurrent Score: 17.39\tActor Loss: -1.04e+00\tCritic Loss: 2.33e-03\n",
      "Episode 138\tExploration: 0.050000\tAverage Score: 9.53\tCurrent Score: 16.07\tActor Loss: -1.05e+00\tCritic Loss: 2.04e-03\n",
      "Episode 139\tExploration: 0.050000\tAverage Score: 9.60\tCurrent Score: 11.16\tActor Loss: -1.06e+00\tCritic Loss: 2.69e-03\n",
      "Episode 140\tExploration: 0.050000\tAverage Score: 9.67\tCurrent Score: 11.25\tActor Loss: -1.06e+00\tCritic Loss: 2.35e-03\n",
      "Episode 141\tExploration: 0.050000\tAverage Score: 9.74\tCurrent Score: 11.63\tActor Loss: -1.07e+00\tCritic Loss: 2.34e-03\n",
      "Episode 142\tExploration: 0.050000\tAverage Score: 9.79\tCurrent Score: 9.46\tActor Loss: -1.08e+00\tCritic Loss: 2.63e-03\n",
      "Episode 143\tExploration: 0.050000\tAverage Score: 9.80\tCurrent Score: 7.45\tActor Loss: -1.09e+00\tCritic Loss: 2.40e-03\n",
      "Episode 144\tExploration: 0.050000\tAverage Score: 9.85\tCurrent Score: 13.16\tActor Loss: -1.10e+00\tCritic Loss: 2.42e-03\n",
      "Episode 145\tExploration: 0.050000\tAverage Score: 9.88\tCurrent Score: 9.49\tActor Loss: -1.10e+00\tCritic Loss: 2.43e-03\n",
      "Episode 146\tExploration: 0.050000\tAverage Score: 9.95\tCurrent Score: 13.52\tActor Loss: -1.11e+00\tCritic Loss: 2.34e-03\n",
      "Episode 147\tExploration: 0.050000\tAverage Score: 9.99\tCurrent Score: 11.59\tActor Loss: -1.12e+00\tCritic Loss: 2.39e-03\n",
      "Episode 148\tExploration: 0.050000\tAverage Score: 10.00\tCurrent Score: 11.94\tActor Loss: -1.13e+00\tCritic Loss: 2.70e-03\n",
      "Episode 149\tExploration: 0.050000\tAverage Score: 10.15\tCurrent Score: 22.34\tActor Loss: -1.13e+00\tCritic Loss: 2.54e-03\n",
      "Episode 150\tExploration: 0.050000\tAverage Score: 10.30\tCurrent Score: 21.15\tActor Loss: -1.15e+00\tCritic Loss: 2.77e-03\n",
      "Episode 151\tExploration: 0.050000\tAverage Score: 10.33\tCurrent Score: 12.78\tActor Loss: -1.16e+00\tCritic Loss: 2.47e-03\n",
      "Episode 152\tExploration: 0.050000\tAverage Score: 10.41\tCurrent Score: 16.72\tActor Loss: -1.16e+00\tCritic Loss: 3.04e-03\n",
      "Episode 153\tExploration: 0.050000\tAverage Score: 10.51\tCurrent Score: 19.96\tActor Loss: -1.17e+00\tCritic Loss: 2.48e-03\n",
      "Episode 154\tExploration: 0.050000\tAverage Score: 10.61\tCurrent Score: 15.46\tActor Loss: -1.18e+00\tCritic Loss: 2.99e-03\n",
      "Episode 155\tExploration: 0.050000\tAverage Score: 10.68\tCurrent Score: 16.51\tActor Loss: -1.19e+00\tCritic Loss: 2.86e-03\n",
      "Episode 156\tExploration: 0.050000\tAverage Score: 10.68\tCurrent Score: 8.20\tActor Loss: -1.20e+00\tCritic Loss: 2.89e-03\n",
      "Episode 157\tExploration: 0.050000\tAverage Score: 10.73\tCurrent Score: 13.67\tActor Loss: -1.20e+00\tCritic Loss: 2.74e-03\n",
      "Episode 158\tExploration: 0.050000\tAverage Score: 10.75\tCurrent Score: 12.93\tActor Loss: -1.21e+00\tCritic Loss: 3.47e-03\n",
      "Episode 159\tExploration: 0.050000\tAverage Score: 10.97\tCurrent Score: 27.95\tActor Loss: -1.22e+00\tCritic Loss: 2.76e-03\n",
      "Episode 160\tExploration: 0.050000\tAverage Score: 10.98\tCurrent Score: 9.56\tActor Loss: -1.23e+00\tCritic Loss: 3.00e-03\n",
      "Episode 161\tExploration: 0.050000\tAverage Score: 11.08\tCurrent Score: 15.70\tActor Loss: -1.24e+00\tCritic Loss: 3.02e-03\n",
      "Episode 162\tExploration: 0.050000\tAverage Score: 11.19\tCurrent Score: 16.61\tActor Loss: -1.25e+00\tCritic Loss: 3.14e-03\n",
      "Episode 163\tExploration: 0.050000\tAverage Score: 11.17\tCurrent Score: 10.86\tActor Loss: -1.25e+00\tCritic Loss: 2.97e-03\n",
      "Episode 164\tExploration: 0.050000\tAverage Score: 11.33\tCurrent Score: 16.95\tActor Loss: -1.26e+00\tCritic Loss: 2.65e-03\n",
      "Episode 165\tExploration: 0.050000\tAverage Score: 11.43\tCurrent Score: 18.79\tActor Loss: -1.27e+00\tCritic Loss: 2.98e-03\n",
      "Episode 166\tExploration: 0.050000\tAverage Score: 11.53\tCurrent Score: 18.60\tActor Loss: -1.28e+00\tCritic Loss: 3.07e-03\n",
      "Episode 167\tExploration: 0.050000\tAverage Score: 11.70\tCurrent Score: 22.54\tActor Loss: -1.29e+00\tCritic Loss: 3.06e-03\n",
      "Episode 168\tExploration: 0.050000\tAverage Score: 11.83\tCurrent Score: 16.72\tActor Loss: -1.30e+00\tCritic Loss: 3.02e-03\n",
      "Episode 169\tExploration: 0.050000\tAverage Score: 11.97\tCurrent Score: 24.92\tActor Loss: -1.31e+00\tCritic Loss: 3.02e-03\n",
      "Episode 170\tExploration: 0.050000\tAverage Score: 11.98\tCurrent Score: 15.98\tActor Loss: -1.31e+00\tCritic Loss: 3.30e-03\n",
      "Episode 171\tExploration: 0.050000\tAverage Score: 12.06\tCurrent Score: 19.55\tActor Loss: -1.33e+00\tCritic Loss: 3.53e-03\n",
      "Episode 172\tExploration: 0.050000\tAverage Score: 12.20\tCurrent Score: 21.38\tActor Loss: -1.34e+00\tCritic Loss: 3.29e-03\n",
      "Episode 173\tExploration: 0.050000\tAverage Score: 12.28\tCurrent Score: 17.01\tActor Loss: -1.34e+00\tCritic Loss: 3.24e-03\n",
      "Episode 174\tExploration: 0.050000\tAverage Score: 12.37\tCurrent Score: 17.48\tActor Loss: -1.35e+00\tCritic Loss: 3.30e-03\n",
      "Episode 175\tExploration: 0.050000\tAverage Score: 12.57\tCurrent Score: 23.02\tActor Loss: -1.36e+00\tCritic Loss: 3.35e-03\n",
      "Episode 176\tExploration: 0.050000\tAverage Score: 12.67\tCurrent Score: 19.56\tActor Loss: -1.37e+00\tCritic Loss: 3.21e-03\n",
      "Episode 177\tExploration: 0.050000\tAverage Score: 12.74\tCurrent Score: 20.13\tActor Loss: -1.38e+00\tCritic Loss: 3.05e-03\n",
      "Episode 178\tExploration: 0.050000\tAverage Score: 12.84\tCurrent Score: 15.87\tActor Loss: -1.39e+00\tCritic Loss: 3.89e-03\n",
      "Episode 179\tExploration: 0.050000\tAverage Score: 12.95\tCurrent Score: 16.31\tActor Loss: -1.40e+00\tCritic Loss: 3.50e-03\n",
      "Episode 180\tExploration: 0.050000\tAverage Score: 13.05\tCurrent Score: 16.86\tActor Loss: -1.40e+00\tCritic Loss: 3.55e-03\n",
      "Episode 181\tExploration: 0.050000\tAverage Score: 13.17\tCurrent Score: 18.09\tActor Loss: -1.41e+00\tCritic Loss: 3.34e-03\n",
      "Episode 182\tExploration: 0.050000\tAverage Score: 13.29\tCurrent Score: 17.75\tActor Loss: -1.42e+00\tCritic Loss: 3.33e-03\n",
      "Episode 183\tExploration: 0.050000\tAverage Score: 13.34\tCurrent Score: 16.83\tActor Loss: -1.43e+00\tCritic Loss: 3.66e-03\n",
      "Episode 184\tExploration: 0.050000\tAverage Score: 13.56\tCurrent Score: 33.59\tActor Loss: -1.44e+00\tCritic Loss: 3.49e-03\n",
      "Episode 185\tExploration: 0.050000\tAverage Score: 13.71\tCurrent Score: 21.17\tActor Loss: -1.45e+00\tCritic Loss: 3.66e-03\n",
      "Episode 186\tExploration: 0.050000\tAverage Score: 13.76\tCurrent Score: 14.29\tActor Loss: -1.46e+00\tCritic Loss: 3.68e-03\n",
      "Episode 187\tExploration: 0.050000\tAverage Score: 13.91\tCurrent Score: 21.00\tActor Loss: -1.47e+00\tCritic Loss: 4.04e-03\n",
      "Episode 188\tExploration: 0.050000\tAverage Score: 14.12\tCurrent Score: 25.46\tActor Loss: -1.48e+00\tCritic Loss: 3.78e-03\n",
      "Episode 189\tExploration: 0.050000\tAverage Score: 14.14\tCurrent Score: 21.61\tActor Loss: -1.49e+00\tCritic Loss: 4.14e-03\n",
      "Episode 190\tExploration: 0.050000\tAverage Score: 14.31\tCurrent Score: 26.44\tActor Loss: -1.50e+00\tCritic Loss: 3.48e-03\n",
      "Episode 191\tExploration: 0.050000\tAverage Score: 14.38\tCurrent Score: 22.96\tActor Loss: -1.51e+00\tCritic Loss: 4.31e-03\n",
      "Episode 192\tExploration: 0.050000\tAverage Score: 14.41\tCurrent Score: 13.84\tActor Loss: -1.52e+00\tCritic Loss: 4.74e-03\n",
      "Episode 193\tExploration: 0.050000\tAverage Score: 14.48\tCurrent Score: 21.74\tActor Loss: -1.53e+00\tCritic Loss: 3.54e-03\n",
      "Episode 194\tExploration: 0.050000\tAverage Score: 14.65\tCurrent Score: 25.18\tActor Loss: -1.54e+00\tCritic Loss: 4.12e-03\n",
      "Episode 195\tExploration: 0.050000\tAverage Score: 14.71\tCurrent Score: 18.63\tActor Loss: -1.55e+00\tCritic Loss: 4.33e-03\n",
      "Episode 196\tExploration: 0.050000\tAverage Score: 14.91\tCurrent Score: 27.19\tActor Loss: -1.57e+00\tCritic Loss: 4.32e-03\n",
      "Episode 197\tExploration: 0.050000\tAverage Score: 15.08\tCurrent Score: 24.49\tActor Loss: -1.58e+00\tCritic Loss: 4.77e-03\n",
      "Episode 198\tExploration: 0.050000\tAverage Score: 15.20\tCurrent Score: 23.93\tActor Loss: -1.59e+00\tCritic Loss: 4.66e-03\n",
      "Episode 199\tExploration: 0.050000\tAverage Score: 15.31\tCurrent Score: 22.96\tActor Loss: -1.59e+00\tCritic Loss: 3.71e-03\n",
      "Episode 200\tExploration: 0.050000\tAverage Score: 15.45\tCurrent Score: 25.40\tActor Loss: -1.60e+00\tCritic Loss: 3.72e-03\n",
      "Episode 200\tAverage Score: 15.45\n",
      "Episode 201\tExploration: 0.050000\tAverage Score: 15.63\tCurrent Score: 29.26\tActor Loss: -1.62e+00\tCritic Loss: 4.69e-03\n",
      "Episode 202\tExploration: 0.050000\tAverage Score: 15.79\tCurrent Score: 28.05\tActor Loss: -1.63e+00\tCritic Loss: 4.58e-03\n",
      "Episode 203\tExploration: 0.050000\tAverage Score: 15.91\tCurrent Score: 18.44\tActor Loss: -1.64e+00\tCritic Loss: 4.79e-03\n",
      "Episode 204\tExploration: 0.050000\tAverage Score: 16.02\tCurrent Score: 22.82\tActor Loss: -1.65e+00\tCritic Loss: 4.54e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 205\tExploration: 0.050000\tAverage Score: 16.26\tCurrent Score: 31.87\tActor Loss: -1.66e+00\tCritic Loss: 4.49e-03\n",
      "Episode 206\tExploration: 0.050000\tAverage Score: 16.44\tCurrent Score: 29.45\tActor Loss: -1.68e+00\tCritic Loss: 5.19e-03\n",
      "Episode 207\tExploration: 0.050000\tAverage Score: 16.61\tCurrent Score: 26.46\tActor Loss: -1.69e+00\tCritic Loss: 4.79e-03\n",
      "Episode 208\tExploration: 0.050000\tAverage Score: 16.69\tCurrent Score: 15.19\tActor Loss: -1.70e+00\tCritic Loss: 5.30e-03\n",
      "Episode 209\tExploration: 0.050000\tAverage Score: 16.77\tCurrent Score: 20.21\tActor Loss: -1.71e+00\tCritic Loss: 5.60e-03\n",
      "Episode 210\tExploration: 0.050000\tAverage Score: 16.83\tCurrent Score: 17.09\tActor Loss: -1.72e+00\tCritic Loss: 5.22e-03\n",
      "Episode 211\tExploration: 0.050000\tAverage Score: 17.08\tCurrent Score: 32.85\tActor Loss: -1.73e+00\tCritic Loss: 5.38e-03\n",
      "Episode 212\tExploration: 0.050000\tAverage Score: 17.25\tCurrent Score: 25.07\tActor Loss: -1.75e+00\tCritic Loss: 5.15e-03\n",
      "Episode 213\tExploration: 0.050000\tAverage Score: 17.37\tCurrent Score: 20.16\tActor Loss: -1.76e+00\tCritic Loss: 4.41e-03\n",
      "Episode 214\tExploration: 0.050000\tAverage Score: 17.52\tCurrent Score: 24.98\tActor Loss: -1.77e+00\tCritic Loss: 5.64e-03\n",
      "Episode 215\tExploration: 0.050000\tAverage Score: 17.57\tCurrent Score: 19.88\tActor Loss: -1.78e+00\tCritic Loss: 5.70e-03\n",
      "Episode 216\tExploration: 0.050000\tAverage Score: 17.79\tCurrent Score: 28.79\tActor Loss: -1.80e+00\tCritic Loss: 5.06e-03\n",
      "Episode 217\tExploration: 0.050000\tAverage Score: 17.88\tCurrent Score: 23.27\tActor Loss: -1.81e+00\tCritic Loss: 5.65e-03\n",
      "Episode 218\tExploration: 0.050000\tAverage Score: 18.01\tCurrent Score: 19.91\tActor Loss: -1.82e+00\tCritic Loss: 4.86e-03\n",
      "Episode 219\tExploration: 0.050000\tAverage Score: 18.14\tCurrent Score: 22.59\tActor Loss: -1.82e+00\tCritic Loss: 5.26e-03\n",
      "Episode 220\tExploration: 0.050000\tAverage Score: 18.36\tCurrent Score: 32.94\tActor Loss: -1.84e+00\tCritic Loss: 5.17e-03\n",
      "Episode 221\tExploration: 0.050000\tAverage Score: 18.53\tCurrent Score: 24.48\tActor Loss: -1.86e+00\tCritic Loss: 4.77e-03\n",
      "Episode 222\tExploration: 0.050000\tAverage Score: 18.76\tCurrent Score: 34.36\tActor Loss: -1.87e+00\tCritic Loss: 5.08e-03\n",
      "Episode 223\tExploration: 0.050000\tAverage Score: 18.97\tCurrent Score: 31.64\tActor Loss: -1.88e+00\tCritic Loss: 4.46e-03\n",
      "Episode 224\tExploration: 0.050000\tAverage Score: 19.02\tCurrent Score: 15.96\tActor Loss: -1.88e+00\tCritic Loss: 6.25e-03\n",
      "Episode 225\tExploration: 0.050000\tAverage Score: 19.20\tCurrent Score: 32.09\tActor Loss: -1.90e+00\tCritic Loss: 5.62e-03\n",
      "Episode 226\tExploration: 0.050000\tAverage Score: 19.34\tCurrent Score: 25.88\tActor Loss: -1.92e+00\tCritic Loss: 5.97e-03\n",
      "Episode 227\tExploration: 0.050000\tAverage Score: 19.32\tCurrent Score: 17.03\tActor Loss: -1.93e+00\tCritic Loss: 5.74e-03\n",
      "Episode 228\tExploration: 0.050000\tAverage Score: 19.38\tCurrent Score: 18.10\tActor Loss: -1.94e+00\tCritic Loss: 5.50e-03\n",
      "Episode 229\tExploration: 0.050000\tAverage Score: 19.55\tCurrent Score: 32.93\tActor Loss: -1.95e+00\tCritic Loss: 6.90e-03\n",
      "Episode 230\tExploration: 0.050000\tAverage Score: 19.70\tCurrent Score: 21.87\tActor Loss: -1.96e+00\tCritic Loss: 5.76e-03\n",
      "Episode 231\tExploration: 0.050000\tAverage Score: 19.73\tCurrent Score: 14.08\tActor Loss: -1.97e+00\tCritic Loss: 5.98e-03\n",
      "Episode 232\tExploration: 0.050000\tAverage Score: 19.94\tCurrent Score: 30.47\tActor Loss: -1.99e+00\tCritic Loss: 6.96e-03\n",
      "Episode 233\tExploration: 0.050000\tAverage Score: 20.00\tCurrent Score: 22.10\tActor Loss: -1.99e+00\tCritic Loss: 5.56e-03\n",
      "Episode 234\tExploration: 0.050000\tAverage Score: 20.24\tCurrent Score: 33.04\tActor Loss: -2.01e+00\tCritic Loss: 6.48e-03\n",
      "Episode 235\tExploration: 0.050000\tAverage Score: 20.40\tCurrent Score: 30.55\tActor Loss: -2.02e+00\tCritic Loss: 6.19e-03\n",
      "Episode 236\tExploration: 0.050000\tAverage Score: 20.55\tCurrent Score: 32.78\tActor Loss: -2.03e+00\tCritic Loss: 6.67e-03\n",
      "Episode 237\tExploration: 0.050000\tAverage Score: 20.68\tCurrent Score: 30.49\tActor Loss: -2.05e+00\tCritic Loss: 6.39e-03\n",
      "Episode 238\tExploration: 0.050000\tAverage Score: 20.87\tCurrent Score: 34.18\tActor Loss: -2.05e+00\tCritic Loss: 6.96e-03\n",
      "Episode 239\tExploration: 0.050000\tAverage Score: 20.92\tCurrent Score: 16.66\tActor Loss: -2.06e+00\tCritic Loss: 6.43e-03\n",
      "Episode 240\tExploration: 0.050000\tAverage Score: 21.16\tCurrent Score: 35.00\tActor Loss: -2.08e+00\tCritic Loss: 6.37e-03\n",
      "Episode 241\tExploration: 0.050000\tAverage Score: 21.31\tCurrent Score: 27.11\tActor Loss: -2.09e+00\tCritic Loss: 6.01e-03\n",
      "Episode 242\tExploration: 0.050000\tAverage Score: 21.46\tCurrent Score: 24.58\tActor Loss: -2.11e+00\tCritic Loss: 6.65e-03\n",
      "Episode 243\tExploration: 0.050000\tAverage Score: 21.62\tCurrent Score: 22.64\tActor Loss: -2.11e+00\tCritic Loss: 5.93e-03\n",
      "Episode 244\tExploration: 0.050000\tAverage Score: 21.83\tCurrent Score: 34.27\tActor Loss: -2.13e+00\tCritic Loss: 7.30e-03\n",
      "Episode 245\tExploration: 0.050000\tAverage Score: 22.05\tCurrent Score: 31.54\tActor Loss: -2.14e+00\tCritic Loss: 7.39e-03\n",
      "Episode 246\tExploration: 0.050000\tAverage Score: 22.18\tCurrent Score: 27.04\tActor Loss: -2.16e+00\tCritic Loss: 6.10e-03\n",
      "Episode 247\tExploration: 0.050000\tAverage Score: 22.40\tCurrent Score: 33.61\tActor Loss: -2.18e+00\tCritic Loss: 5.60e-03\n",
      "Episode 248\tExploration: 0.050000\tAverage Score: 22.65\tCurrent Score: 36.13\tActor Loss: -2.18e+00\tCritic Loss: 8.05e-03\n",
      "Episode 249\tExploration: 0.050000\tAverage Score: 22.79\tCurrent Score: 37.26\tActor Loss: -2.20e+00\tCritic Loss: 8.68e-03\n",
      "Episode 250\tExploration: 0.050000\tAverage Score: 22.89\tCurrent Score: 31.14\tActor Loss: -2.22e+00\tCritic Loss: 6.65e-03\n",
      "Episode 251\tExploration: 0.050000\tAverage Score: 23.15\tCurrent Score: 38.16\tActor Loss: -2.23e+00\tCritic Loss: 8.31e-03\n",
      "Episode 252\tExploration: 0.050000\tAverage Score: 23.32\tCurrent Score: 34.08\tActor Loss: -2.25e+00\tCritic Loss: 7.21e-03\n",
      "Episode 253\tExploration: 0.050000\tAverage Score: 23.45\tCurrent Score: 32.71\tActor Loss: -2.26e+00\tCritic Loss: 6.49e-03\n",
      "Episode 254\tExploration: 0.050000\tAverage Score: 23.61\tCurrent Score: 31.14\tActor Loss: -2.27e+00\tCritic Loss: 7.55e-03\n",
      "Episode 255\tExploration: 0.050000\tAverage Score: 23.69\tCurrent Score: 25.15\tActor Loss: -2.28e+00\tCritic Loss: 7.14e-03\n",
      "Episode 256\tExploration: 0.050000\tAverage Score: 23.86\tCurrent Score: 24.87\tActor Loss: -2.30e+00\tCritic Loss: 8.40e-03\n",
      "Episode 257\tExploration: 0.050000\tAverage Score: 24.01\tCurrent Score: 28.68\tActor Loss: -2.32e+00\tCritic Loss: 1.01e-02\n",
      "Episode 258\tExploration: 0.050000\tAverage Score: 24.21\tCurrent Score: 32.75\tActor Loss: -2.32e+00\tCritic Loss: 8.36e-03\n",
      "Episode 259\tExploration: 0.050000\tAverage Score: 24.20\tCurrent Score: 27.59\tActor Loss: -2.34e+00\tCritic Loss: 7.99e-03\n",
      "Episode 260\tExploration: 0.050000\tAverage Score: 24.47\tCurrent Score: 36.52\tActor Loss: -2.36e+00\tCritic Loss: 7.70e-03\n",
      "Episode 261\tExploration: 0.050000\tAverage Score: 24.69\tCurrent Score: 36.88\tActor Loss: -2.38e+00\tCritic Loss: 7.41e-03\n",
      "Episode 262\tExploration: 0.050000\tAverage Score: 24.83\tCurrent Score: 31.58\tActor Loss: -2.39e+00\tCritic Loss: 6.54e-03\n",
      "Episode 263\tExploration: 0.050000\tAverage Score: 25.07\tCurrent Score: 34.32\tActor Loss: -2.41e+00\tCritic Loss: 8.17e-03\n",
      "Episode 264\tExploration: 0.050000\tAverage Score: 25.25\tCurrent Score: 34.54\tActor Loss: -2.42e+00\tCritic Loss: 8.59e-03\n",
      "Episode 265\tExploration: 0.050000\tAverage Score: 25.38\tCurrent Score: 32.69\tActor Loss: -2.43e+00\tCritic Loss: 8.14e-03\n",
      "Episode 266\tExploration: 0.050000\tAverage Score: 25.58\tCurrent Score: 37.68\tActor Loss: -2.45e+00\tCritic Loss: 7.80e-03\n",
      "Episode 267\tExploration: 0.050000\tAverage Score: 25.70\tCurrent Score: 34.81\tActor Loss: -2.46e+00\tCritic Loss: 8.33e-03\n",
      "Episode 268\tExploration: 0.050000\tAverage Score: 25.82\tCurrent Score: 28.54\tActor Loss: -2.47e+00\tCritic Loss: 9.58e-03\n",
      "Episode 269\tExploration: 0.050000\tAverage Score: 25.93\tCurrent Score: 36.65\tActor Loss: -2.49e+00\tCritic Loss: 8.64e-03\n",
      "Episode 270\tExploration: 0.050000\tAverage Score: 26.13\tCurrent Score: 35.41\tActor Loss: -2.51e+00\tCritic Loss: 9.23e-03\n",
      "Episode 271\tExploration: 0.050000\tAverage Score: 26.22\tCurrent Score: 28.65\tActor Loss: -2.52e+00\tCritic Loss: 8.08e-03\n",
      "Episode 272\tExploration: 0.050000\tAverage Score: 26.38\tCurrent Score: 37.48\tActor Loss: -2.53e+00\tCritic Loss: 8.58e-03\n",
      "Episode 273\tExploration: 0.050000\tAverage Score: 26.58\tCurrent Score: 37.04\tActor Loss: -2.55e+00\tCritic Loss: 9.11e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 274\tExploration: 0.050000\tAverage Score: 26.75\tCurrent Score: 34.67\tActor Loss: -2.57e+00\tCritic Loss: 1.09e-02\n",
      "Episode 275\tExploration: 0.050000\tAverage Score: 26.77\tCurrent Score: 25.13\tActor Loss: -2.58e+00\tCritic Loss: 1.01e-02\n",
      "Episode 276\tExploration: 0.050000\tAverage Score: 26.90\tCurrent Score: 31.94\tActor Loss: -2.59e+00\tCritic Loss: 1.09e-02\n",
      "Episode 277\tExploration: 0.050000\tAverage Score: 27.09\tCurrent Score: 39.57\tActor Loss: -2.61e+00\tCritic Loss: 8.79e-03\n",
      "Episode 278\tExploration: 0.050000\tAverage Score: 27.29\tCurrent Score: 35.59\tActor Loss: -2.62e+00\tCritic Loss: 1.11e-02\n",
      "Episode 279\tExploration: 0.050000\tAverage Score: 27.49\tCurrent Score: 36.07\tActor Loss: -2.65e+00\tCritic Loss: 1.02e-02\n",
      "Episode 280\tExploration: 0.050000\tAverage Score: 27.69\tCurrent Score: 36.83\tActor Loss: -2.66e+00\tCritic Loss: 1.09e-02\n",
      "Episode 281\tExploration: 0.050000\tAverage Score: 27.90\tCurrent Score: 39.29\tActor Loss: -2.67e+00\tCritic Loss: 8.40e-03\n",
      "Episode 282\tExploration: 0.050000\tAverage Score: 28.10\tCurrent Score: 37.87\tActor Loss: -2.69e+00\tCritic Loss: 7.13e-03\n",
      "Episode 283\tExploration: 0.050000\tAverage Score: 28.30\tCurrent Score: 37.44\tActor Loss: -2.71e+00\tCritic Loss: 9.33e-03\n",
      "Episode 284\tExploration: 0.050000\tAverage Score: 28.34\tCurrent Score: 37.40\tActor Loss: -2.73e+00\tCritic Loss: 1.17e-02\n",
      "Episode 285\tExploration: 0.050000\tAverage Score: 28.52\tCurrent Score: 39.36\tActor Loss: -2.74e+00\tCritic Loss: 9.67e-03\n",
      "Episode 286\tExploration: 0.050000\tAverage Score: 28.73\tCurrent Score: 35.07\tActor Loss: -2.77e+00\tCritic Loss: 1.04e-02\n",
      "Episode 287\tExploration: 0.050000\tAverage Score: 28.92\tCurrent Score: 39.53\tActor Loss: -2.78e+00\tCritic Loss: 1.13e-02\n",
      "Episode 288\tExploration: 0.050000\tAverage Score: 29.05\tCurrent Score: 38.70\tActor Loss: -2.79e+00\tCritic Loss: 1.02e-02\n",
      "Episode 289\tExploration: 0.050000\tAverage Score: 29.14\tCurrent Score: 31.02\tActor Loss: -2.81e+00\tCritic Loss: 1.34e-02\n",
      "Episode 290\tExploration: 0.050000\tAverage Score: 29.19\tCurrent Score: 31.49\tActor Loss: -2.83e+00\tCritic Loss: 8.57e-03\n",
      "Episode 291\tExploration: 0.050000\tAverage Score: 29.34\tCurrent Score: 37.91\tActor Loss: -2.83e+00\tCritic Loss: 9.39e-03\n",
      "Episode 292\tExploration: 0.050000\tAverage Score: 29.51\tCurrent Score: 30.86\tActor Loss: -2.85e+00\tCritic Loss: 1.05e-02\n",
      "Episode 293\tExploration: 0.050000\tAverage Score: 29.60\tCurrent Score: 30.03\tActor Loss: -2.87e+00\tCritic Loss: 1.13e-02\n",
      "Episode 294\tExploration: 0.050000\tAverage Score: 29.74\tCurrent Score: 38.97\tActor Loss: -2.88e+00\tCritic Loss: 1.09e-02\n",
      "Episode 295\tExploration: 0.050000\tAverage Score: 29.94\tCurrent Score: 39.03\tActor Loss: -2.90e+00\tCritic Loss: 1.06e-02\n",
      "Episode 296\tExploration: 0.050000\tAverage Score: 30.04\tCurrent Score: 37.57\tActor Loss: -2.92e+00\tCritic Loss: 9.18e-03\n",
      "Episode 296\tAverage Score: 30.04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07c5bef7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(agent)\n",
    "\n",
    "scores, actor_losses, critic_losses = ddpg(n_episodes=N_EPISODES,\n",
    "                                           eps_start=EPS_START, eps_decay=EPS_DECAY, eps_end=EPS_END,\n",
    "                                           max_t=MAX_STEPS, learn_every_step=LEARN_EVERY_STEP)\n",
    "\n",
    "agent.save()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.plot(np.arange(1, len(scores) + 1), scores)\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_xlabel('Episode #')\n",
    "\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax2.plot(np.arange(1, len(actor_losses) + 1), actor_losses)\n",
    "# ax2.legend()\n",
    "ax2.set_ylabel('Actor Loss')\n",
    "ax2.set_xlabel('Episode #')\n",
    "\n",
    "ax3 = fig.add_subplot(313)\n",
    "ax3.plot(np.arange(1, len(critic_losses) + 1), critic_losses)\n",
    "ax3.set_ylabel('Critic Loss')\n",
    "ax3.set_xlabel('Episode #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the values from the log information above and rebuild the training plot as follows. (Refer to the file `one_robot_plot.py`)\n",
    "\n",
    "![training_img](resources/Continuous_Control_DDPG_one_robot.png)\n",
    "\n",
    "From the plot above, the episode is **296** when average score of last 100 episodes larger than 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch the smart Agent to play\n",
    "\n",
    "We load the actor model's parameters to watch the smart agent.\n",
    "\n",
    "**Attention:** The pretrained checkpoints are on GPU machine. There will be an error if you load the checkpoints on non GPU machines, you should do some small changes in Agent#load method in `ddpg_agent.py`. Please refer to [this link](https://pytorch.org/tutorials/beginner/saving_loading_models.html) for hadling the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Steps: 1001, Total Rewards: 39.06999912671745\n"
     ]
    }
   ],
   "source": [
    "agent.load()\n",
    "\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "states = env_info.vector_observations\n",
    "\n",
    "t_step, total_rewards = 0, 0\n",
    "while True:\n",
    "    actions = agent.act(states, add_noise=False)\n",
    "\n",
    "    env_info = env.step(actions)[brain_name]\n",
    "    next_states = env_info.vector_observations\n",
    "    rewards = env_info.rewards\n",
    "    dones = env_info.local_done\n",
    "\n",
    "    states = next_states\n",
    "    t_step += 1\n",
    "    total_rewards += np.mean(rewards)\n",
    "    if np.any(dones):\n",
    "        break\n",
    "\n",
    "print(f\"Total Steps: {t_step}, Total Rewards: {total_rewards}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Close the Unity Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
